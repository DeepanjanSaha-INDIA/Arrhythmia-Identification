{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5120d0c7b9f3f31170ebab5d458b4b4da9232541"
   },
   "source": [
    "# importing the modules Numpy, Pandas, Matplotlib, Sklearn and  DWT module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e77c37aff362dbab906c838f2f1a651b429a2c58",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/mitbih-database\"))\n",
    "# annoation, mitbih-database/mitbih_database\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression , Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n",
    "\n",
    "from sklearn import metrics #for checking the model accuracy\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier # A combine model of many decision t\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Module for discrete wavelet transform\n",
    "import pywt\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b279c4ab8d9552e929253917666fa6e8e06979db"
   },
   "source": [
    "# Randomly selecting files for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7f14c846da9ade7d481608f8bef9ec073c07093",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst1=[i for i in range(100,125)]\n",
    "a=[i+100 for i in [10,20]]\n",
    "for i in a:\n",
    "    lst1.remove(i)\n",
    "lst2=[i for i in range(200,235)]\n",
    "a=[i+200 for i in [4,6,11,16,18,24,25,26,27,29]]\n",
    "for i in a:\n",
    "    lst2.remove(i)\n",
    "lst1+=lst2\n",
    "lst=np.array(lst1)\n",
    "np.random.shuffle(lst)\n",
    "train_lst,test_lst=lst[:43],lst[43:]\n",
    "for i in test_lst:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0f2920c6b86ebb6270efa47224167b61dac86a0"
   },
   "source": [
    "# filtering function:\n",
    "**Inputs:**\n",
    "\n",
    "**x -> df['ML']**\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "**high (arr) -> Bandpass output of the raw (including noise)signal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96fe513e494741acb1c28b183845b8e61987b7a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def filtering(x):\n",
    "    ##--LOW PASS FILTER\n",
    "    x=list(x)\n",
    "    low=[0,0]\n",
    "    x=12*[0]+x\n",
    "    for i,j in zip(range(12,len(x)),range(2,len(x)+2)):\n",
    "        low.append(2*low[j-1]-low[j-2]+x[i]-2*x[i-6]+x[i-12])\n",
    "    low=low[2:]\n",
    "#     print(len(low),len(x))\n",
    "    for i,j in enumerate(low):\n",
    "        low[i]/=35\n",
    "    x=x[12:]\n",
    "#     plt.plot(range(1000),x[:1000],c='r',label='MLII')\n",
    "#     plt.plot(range(1000),low[:1000],c='b',label='Low pass')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "    ##--HIGH PASS FILTER\n",
    "    high=[0]\n",
    "    low=32*[0]+low\n",
    "    for i,j in zip(range(32,len(low)),range(1,len(low)+1)):\n",
    "        high.append(32*low[i-16]-low[i]+low[i-32]-high[j-1])\n",
    "    low=low[32:]\n",
    "    high=high[1:]\n",
    "#     print(len(low),len(high))\n",
    "    for i,j in enumerate(high):\n",
    "        high[i]/=15\n",
    "#     time=[i/360 for i in range(2000)]\n",
    "#     plt.plot(time,x[:2000],c='r',label='Input signal')\n",
    "#     plt.plot(time[:-15],high[15:2000],c='b',label='Filtered output')\n",
    "#     plt.ylabel('in mV')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.title('Bandpassed Filtered signal')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "    return high\n",
    "# bandpass_output=filtering(df['ML'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee98e52f3d27fb7dd463868965d919fa1ac40842"
   },
   "source": [
    "# interpolation function\n",
    "**Using the band pass filter output and index of QRS complex, we are downsampling the points between them to 100 points and returning the list of all these points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7ad295497e530197c2cdbadd0472e2d29c276e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolation(ind,high):\n",
    "    total_peaks=[]\n",
    "    print(len(ind))\n",
    "    for i,j in zip(ind[:-1] , ind[1:]):\n",
    "        diff=(j-i)/100\n",
    "        val=i\n",
    "        arr=[]\n",
    "        for k in range(100):\n",
    "            val+=diff\n",
    "            arr.append(high[round(val)])\n",
    "        total_peaks.append(arr)\n",
    "#     print(len(total_peaks),len(total_peaks[1]))\n",
    "    return total_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7bb9afbb08632f397a9f6ecbc678cd3c6ef530b"
   },
   "source": [
    "# DWT function\n",
    "**Using the result of the reduction_testing() we are applying DWT (Discrete Wavelet Transform) on sets of 100 points and storing the coefficients of that in list and returning it.**\n",
    "\n",
    "**These list of coefficient will act as feature vector for the heart beat.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95b9c56dcf56b395d5922214125bfd84c6df12a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_transform(total_peaks):\n",
    "    for i in range(len(total_peaks)):\n",
    "        cA,cD= pywt.dwt(total_peaks[i], 'db1')\n",
    "        cA.shape=(1,50)\n",
    "        cD.shape=(1,50)\n",
    "        if i==0:\n",
    "            CA=cA.copy()\n",
    "            CD=cD.copy()\n",
    "        else:\n",
    "            CD=np.concatenate((CD,cD))\n",
    "            CA=np.concatenate((CA,cA))\n",
    "#     print(CA.shape)\n",
    "    return CA,CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dba75fb0c7fe2bb32fa9f867aa1498c38e4b905b"
   },
   "source": [
    "# creating_dataframe function:\n",
    "**The CA and CD coefficients returned will be converted into pandas dataframe and it is returned.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ea3c43de8a033470f86ddbbd06f40080a1525c5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creating_dataframe(CA):\n",
    "    train_CA=pd.DataFrame(CA,columns=['f{}'.format(i) for i in range(50)])\n",
    "    return train_CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d65416a550349cb3c9a366855a2f53f96713ef3"
   },
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d77417d5f4704b84d6fd56e65a65ea901a82859c",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset=pd.DataFrame(columns=['f{}'.format(i) for i in range(50)]+['Sample#']+['Type'])\n",
    "    for i in [100]:\n",
    "#         Reading the files\n",
    "        print('{} is processing'.format(i))\n",
    "        df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n",
    "        if i in [102,104]:\n",
    "            df=df[[\"'sample #'\",\"'V5'\"]]\n",
    "            df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n",
    "        else:\n",
    "            df=df[[\"'sample #'\",\"'MLII'\"]]\n",
    "            df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n",
    "        df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n",
    "        an=pd.read_csv(\"../input/annoation/{}annotations.csv\".format(i))\n",
    "        an=an[['Time','Sample#','Type']]\n",
    "#         Creating the Labels ( Category)\n",
    "        an['Type'].replace(to_replace=['N', 'P', 'f', 'p', 'Q', '|', '+', 's', 't', '~', 'L', 'R','A', 'a','x', 'J', 'S','V', 'F','e', 'j', 'n', 'E','[',']','!'],value=[1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,3,3,4,4,4,4,5,5,5], inplace=True)\n",
    "        print(i,an['Type'].unique())\n",
    "#         Preprocessing\n",
    "        bandpass_output=filtering(df['ML'])\n",
    "#         Interpolation\n",
    "        total_peaks=interpolation(an['Sample#'],bandpass_output)\n",
    "#         Discrete Wavelet Transform\n",
    "        CA,CD=wavelet_transform(total_peaks)\n",
    "        print(i,CA.shape,len(an['Type']))\n",
    "        peak2peak=an['Sample#'].diff()\n",
    "        peak2peak=peak2peak[1:]\n",
    "#         Creating the Dataframe\n",
    "        DS=creating_dataframe(CA)\n",
    "        DS=pd.concat([DS,peak2peak],axis=1)\n",
    "        DS=pd.concat([DS,an['Type'][1:]],axis=1)\n",
    "#         Adding the dataframe to dataset\n",
    "        dataset=pd.concat([dataset,DS],axis=0)\n",
    "    \n",
    "    dataset.dropna(inplace=True)\n",
    "    try:\n",
    "        dataset=dataset[dataset['Type']!='\"']\n",
    "        dataset=dataset[dataset['Type']!='/']\n",
    "    except:\n",
    "        pass\n",
    "    dataset['Type']=dataset['Type'].astype('int32')\n",
    "\n",
    "    return dataset\n",
    "ds=create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bd2a57814ccd97d421586029fb635ff88f2d569"
   },
   "source": [
    "# Pan Tompkin's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4bb58d0b73835219a083e968521c70035100f80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(high):\n",
    "    tot=len(high)\n",
    "    ##--DERIVATIVE\n",
    "    deri=[]\n",
    "    high=[0]*2+high+[0]*2\n",
    "    for i in range(2,tot+2):\n",
    "        deri.append((2*high[i+1]-2*high[i-1]+high[i+2]-high[i-2])/8)\n",
    "    high=high[2:-2]\n",
    "#     print(len(deri),len(high))\n",
    "    for i,j in enumerate(deri):\n",
    "        deri[i]*=10\n",
    "    time=[i/360 for i in range(2000)]\n",
    "#     plt.plot(time,deri[:2000],c='r',label='derivative')\n",
    "#     plt.plot(time,high[:2000],c='b',label='bandpass output')\n",
    "#     plt.ylabel('in mV')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.title('Derivative of bandpass signal')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    ##--SQUARE\n",
    "    sq=[]\n",
    "    for i in range(len(deri)):\n",
    "        sq.append(deri[i]*deri[i])\n",
    "#     plt.plot(time,deri[:2000],c='r',label='derivative signal')\n",
    "#     plt.plot(time,sq[:2000],c='b',label='squared output')\n",
    "#     plt.ylabel('in mV')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.title('Squared of derivative signal')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    ##--MOVING AVERAGE\n",
    "    mv=[]\n",
    "    n=30\n",
    "    sq=[0]*n+sq+[0]*n\n",
    "    for i in range(n,len(deri)+n):\n",
    "        mv.append(sum(sq[i:i+n])/n)\n",
    "    sq=sq[n:-n]\n",
    "#     plt.plot(time,sq[:2000],c='r',label='squared signal')\n",
    "#     plt.plot(time,mv[:2000],c='b',label='moving average output')\n",
    "#     plt.ylabel('in mV')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.title('Moving average of squared signal')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    return mv\n",
    "# mv=preprocessing(bandpass_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0b5f21d29bcb74670ad9f23b921f1634f00cafc"
   },
   "source": [
    "# Adaptive threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "effec4db34f8075743a73809dcdd6070d9ce50e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold(mv,bp):\n",
    "    beat_ind,beat_no=[],0\n",
    "    spk,npk,thresh1,thresh2,thresh=0,0,0,0,[]\n",
    "    i,prev=0,False\n",
    "    length=len(mv)\n",
    "    while i<length:\n",
    "        if mv[i]>thresh1:\n",
    "            spk=spk=0.125*mv[i]+0.875*spk\n",
    "        else:\n",
    "            npk=0.125*mv[i]+0.875*npk\n",
    "        thresh1=0.75*npk+0.25*spk\n",
    "        thresh.append(200*thresh1)\n",
    "        thresh2=0.5*thresh1\n",
    "        if mv[i]>thresh1 and prev==False:\n",
    "            beat_no+=1\n",
    "            prev=True\n",
    "            beat_ind.append(i)\n",
    "        if mv[i]<thresh1 and prev==True:\n",
    "            prev=False\n",
    "        i+=1\n",
    "#     for i,j in enumerate(bp):\n",
    "#         bp[i]*=60\n",
    "#     time=[i/360 for i in range(2000)]\n",
    "#     plt.plot(time,bp[:2000],c='r',label='filtered signal')\n",
    "#     plt.plot(time,thresh[:2000],c='b',label='threshold output')\n",
    "#     plt.ylabel('in mV')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.title('Threshold variation with the input filtered signal')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    return beat_ind,beat_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b40d4ea5f9845fd97b9d142e639c13fe8db54cb"
   },
   "source": [
    "# Creating the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21d51b9fa0886df6b267eab2554d2b7cb7a3321b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion(pre,org):\n",
    "    i,j=0,0\n",
    "    tp,fp,fn=0,0,0\n",
    "    while i<len(pre) and j<len(org):\n",
    "        if abs(pre[i]-org['Sample#'][j])<40:\n",
    "            tp+=1\n",
    "            i+=1\n",
    "            j+=1\n",
    "        elif pre[i]<org['Sample#'][j]:\n",
    "            i+=1\n",
    "        else:\n",
    "            j+=1\n",
    "    fn=len(org)-tp\n",
    "    fp=len(pre)-tp\n",
    "    df=pd.DataFrame({'Present_Total_Heartbeat':[len(org)],'Predicted_Total_Heartbeat':[len(pre)],'TP':[tp],'FP':[fp],'FN':[fn]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b7f18f401bc9c614475825ef1c12d6d0e7da37a"
   },
   "source": [
    "# Testing the patients data with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8e90be484322c497a6e722883593bd24f15d82e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e30aba593a681064c6e7959a83ce74dcacfe73e9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=joblib.load('../input/trained-randomforest/Decison_Tree2.sav')\n",
    "dt=joblib.load('../input/trained-randomforest/Decison_Tree2.sav')\n",
    "def testing():\n",
    "    for i in test_lst:\n",
    "        print('{} is processing'.format(i))\n",
    "        df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n",
    "        an=pd.read_csv(\"../input/annoation/{}annotations.csv\".format(i))\n",
    "        an=an[['Sample#','Type']]\n",
    "        an['Type'].replace(to_replace=['N', 'P', 'f', 'p', 'Q', '|', '+', 's', 't', '~', 'L', 'R','A', 'a','x', 'J', 'S','V', 'F','e', 'j', 'n', 'E','[',']','!'],value=[1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,3,3,4,4,4,4,5,5,5], inplace=True)\n",
    "        if i in [102,104]:\n",
    "            df=df[[\"'sample #'\",\"'V5'\"]]\n",
    "            df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n",
    "        else:\n",
    "            df=df[[\"'sample #'\",\"'MLII'\"]]\n",
    "            df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n",
    "        df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n",
    "#         Filtering\n",
    "        bandpass_output=filtering(df['ML'])\n",
    "#         print(df.head())\n",
    "#         Preprocessing\n",
    "        mv=preprocessing(bandpass_output)\n",
    "        beat_ind,beat_no=threshold(mv,bandpass_output)\n",
    "#         Interpolation\n",
    "        total_peaks=interpolation(beat_ind,bandpass_output)\n",
    "#         Discrete Wavelet Transform\n",
    "        CA,CD=wavelet_transform(total_peaks)\n",
    "        pdSeries=pd.DataFrame([i-j for i,j in zip(beat_ind[1:],beat_ind[:-1])],columns=['Sample#'])\n",
    "        DS=creating_dataframe(CA)\n",
    "        DS=pd.concat([DS,pdSeries],axis=1)\n",
    "#         print(DS.shape)\n",
    "        res_rf=rf.predict(DS)\n",
    "        uni,count=np.unique(res_rf,return_counts=True)\n",
    "        for i,j in zip(uni,count):\n",
    "            print('For category {}, total no. of heartbeat {}'.format(i,j))\n",
    "\n",
    "testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ebe9390e3f1b6fc17f3cdd71fd95d18e457a976d"
   },
   "source": [
    "# Sensitivity and Positive predictivity of heartbeat detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46693a3b87f50aa1d919f51d123cda2a08635823",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detection_accuracy():\n",
    "    dataset=pd.DataFrame(columns=['Present_Total_Heartbeat','Predicted_Total_Heartbeat','TP','FP','FN'])\n",
    "    for i in lst1:\n",
    "        print('{} is processing'.format(i))\n",
    "        df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n",
    "        an=pd.read_csv(\"../input/annoation/{}annotations.csv\".format(i))\n",
    "        an=an[['Sample#']]\n",
    "        if i in [102,104]:\n",
    "            df=df[[\"'sample #'\",\"'V5'\"]]\n",
    "            df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n",
    "        else:\n",
    "            df=df[[\"'sample #'\",\"'MLII'\"]]\n",
    "            df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n",
    "        df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n",
    "#         Filtering\n",
    "        bandpass_output=filtering(df['ML'])\n",
    "#         Preprocessing\n",
    "        mv=preprocessing(bandpass_output)\n",
    "        beat_ind,beat_no=threshold(mv,bandpass_output)\n",
    "#         Confusion Matrix\n",
    "        file_info=confusion(beat_ind,an)\n",
    "        dataset=pd.concat([dataset,file_info])\n",
    "    print(dataset)\n",
    "    print('Sensivity : {}'.format(dataset['TP'].sum()/(dataset['TP'].sum()+dataset['FN'].sum())))\n",
    "    print('Positive predictivity : {}'.format(dataset['TP'].sum()/(dataset['TP'].sum()+dataset['FP'].sum())))\n",
    "\n",
    "detection_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45cc8a36fd25f86337f9babac2d1fba8f1a4ee01",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
