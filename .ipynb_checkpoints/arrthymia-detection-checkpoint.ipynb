{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5120d0c7b9f3f31170ebab5d458b4b4da9232541"
   },
   "source": [
    "# importing the modules Numpy, Pandas, Matplotlib, Sklearn and  DWT module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e77c37aff362dbab906c838f2f1a651b429a2c58",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/mitbih-database\"))\n",
    "# annoation, mitbih-database/mitbih_database\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression , Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n",
    "\n",
    "from sklearn import metrics #for checking the model accuracy\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier # A combine model of many decision t\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Module for discrete wavelet transform\n",
    "import pywt\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b279c4ab8d9552e929253917666fa6e8e06979db"
   },
   "source": [
    "# Randomly selecting files for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7f14c846da9ade7d481608f8bef9ec073c07093",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst1=[i for i in range(100,125)]\n",
    "a=[i+100 for i in [10,20]]\n",
    "for i in a:\n",
    "    lst1.remove(i)\n",
    "lst2=[i for i in range(200,235)]\n",
    "a=[i+200 for i in [4,6,11,16,18,24,25,26,27,29]]\n",
    "for i in a:\n",
    "    lst2.remove(i)\n",
    "lst1+=lst2\n",
    "lst=np.array(lst1)\n",
    "np.random.shuffle(lst)\n",
    "train_lst,test_lst=lst[:43],lst[43:]\n",
    "for i in test_lst:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0f2920c6b86ebb6270efa47224167b61dac86a0"
   },
   "source": [
    "# filtering function:\n",
    "**Inputs:**\n",
    "\n",
    "**x -> df['ML']**\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "**high (arr) -> Bandpass output of the raw (including noise)signal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96fe513e494741acb1c28b183845b8e61987b7a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filtering(x):\n",
    "    ##--LOW PASS FILTER\n",
    "    x=list(x)\n",
    "    low=[0,0]\n",
    "    x=12*[0]+x\n",
    "    for i,j in zip(range(12,len(x)),range(2,len(x)+2)):\n",
    "        low.append(2*low[j-1]-low[j-2]+x[i]-2*x[i-6]+x[i-12])\n",
    "    low=low[2:]\n",
    "#     print(len(low),len(x))\n",
    "    for i,j in enumerate(low):\n",
    "        low[i]/=35\n",
    "    x=x[12:]\n",
    "    ##--HIGH PASS FILTER\n",
    "    high=[0]\n",
    "    low=32*[0]+low\n",
    "    for i,j in zip(range(32,len(low)),range(1,len(low)+1)):\n",
    "        high.append(32*low[i-16]-low[i]+low[i-32]-high[j-1])\n",
    "    low=low[32:]\n",
    "    high=high[1:]\n",
    "#     print(len(low),len(high))\n",
    "    for i,j in enumerate(high):\n",
    "        high[i]/=15\n",
    "#     time=[i/360 for i in range(2000)]\n",
    "#     plt.plot(time,x[:2000],c='r',label='Input signal')\n",
    "#     plt.plot(time,high[:2000],c='b',label='Bandpass output')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.ylabel('Voltage (in mv)')\n",
    "#     plt.title('Plot between Input signal and Bandpass output')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "    return high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee98e52f3d27fb7dd463868965d919fa1ac40842"
   },
   "source": [
    "# interpolation function\n",
    "**Using the band pass filter output and index of QRS complex, we are downsampling the points between them to 100 points and returning the list of all these points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7ad295497e530197c2cdbadd0472e2d29c276e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolation(ind,high):\n",
    "    total_peaks=[]\n",
    "#     print(len(ind))\n",
    "    for i,j in zip(ind[:-1] , ind[1:]):\n",
    "        diff=(j-i)/100\n",
    "        val=i\n",
    "        arr=[]\n",
    "        for k in range(100):\n",
    "            val+=diff\n",
    "            arr.append(high[round(val)])\n",
    "        total_peaks.append(arr)\n",
    "#     print(len(total_peaks),len(total_peaks[1]))\n",
    "    return total_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7bb9afbb08632f397a9f6ecbc678cd3c6ef530b"
   },
   "source": [
    "# DWT function\n",
    "**Using the result of the reduction_testing() we are applying DWT (Discrete Wavelet Transform) on sets of 100 points and storing the coefficients of that in list and returning it.**\n",
    "\n",
    "**These list of coefficient will act as feature vector for the heart beat.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95b9c56dcf56b395d5922214125bfd84c6df12a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_transform(total_peaks):\n",
    "    for i in range(len(total_peaks)):\n",
    "        cA,cD= pywt.dwt(total_peaks[i], 'db1')\n",
    "        cA.shape=(1,50)\n",
    "        cD.shape=(1,50)\n",
    "        if i==0:\n",
    "            CA=cA.copy()\n",
    "            CD=cD.copy()\n",
    "        else:\n",
    "            CD=np.concatenate((CD,cD))\n",
    "            CA=np.concatenate((CA,cA))\n",
    "#     print(CA.shape)\n",
    "    return CA,CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dba75fb0c7fe2bb32fa9f867aa1498c38e4b905b"
   },
   "source": [
    "# creating_dataframe function:\n",
    "**The CA and CD coefficients returned will be converted into pandas dataframe and it is returned.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ea3c43de8a033470f86ddbbd06f40080a1525c5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creating_dataframe(CA):\n",
    "    train_CA=pd.DataFrame(CA,columns=['f{}'.format(i) for i in range(50)])\n",
    "    return train_CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d65416a550349cb3c9a366855a2f53f96713ef3"
   },
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d77417d5f4704b84d6fd56e65a65ea901a82859c",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset=pd.DataFrame(columns=['f{}'.format(i) for i in range(50)]+['Sample#']+['Type'])\n",
    "    for i in train_lst:\n",
    "#         Reading the files\n",
    "        print('{} is processing'.format(i))\n",
    "        df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n",
    "        if i in [102,104]:\n",
    "            df=df[[\"'sample #'\",\"'V5'\"]]\n",
    "            df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n",
    "        else:\n",
    "            df=df[[\"'sample #'\",\"'MLII'\"]]\n",
    "            df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n",
    "        df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n",
    "        an=pd.read_csv(\"../input/annoation/{}annotations.csv\".format(i))\n",
    "        an=an[['Time','Sample#','Type']]\n",
    "#         Creating the Labels ( Category)\n",
    "        an['Type'].replace(to_replace=['N', 'P', 'f', 'p', 'Q', '|', '+', 's', 't', '~', 'L', 'R','A', 'a','x', 'J', 'S','V', 'F','e', 'j', 'n', 'E','[',']','!'],value=[1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,3,3,4,4,4,4,5,5,5], inplace=True)\n",
    "        print(i,an['Type'].unique())\n",
    "#         Preprocessing\n",
    "        bandpass_output=filtering(df['ML'])\n",
    "#         Interpolation\n",
    "        total_peaks=interpolation(an['Sample#'],bandpass_output)\n",
    "#         Discrete Wavelet Transform\n",
    "        CA,CD=wavelet_transform(total_peaks)\n",
    "        print(i,CA.shape,len(an['Type']))\n",
    "        peak2peak=an['Sample#'].diff()\n",
    "        peak2peak=peak2peak[1:]\n",
    "#         Creating the Dataframe\n",
    "        DS=creating_dataframe(CA)\n",
    "        DS=pd.concat([DS , peak2peak] , axis =1)\n",
    "        DS=pd.concat([DS,an['Type'][1:]],axis=1)\n",
    "#         Adding the dataframe to dataset\n",
    "        dataset=pd.concat([dataset,DS],axis=0)\n",
    "    \n",
    "    dataset.dropna(inplace=True)\n",
    "    try:\n",
    "        dataset=dataset[dataset['Type']!='\"']\n",
    "        dataset=dataset[dataset['Type']!='/']\n",
    "    except:\n",
    "        pass\n",
    "    dataset['Type']=dataset['Type'].astype('int32')\n",
    "    \n",
    "    return dataset\n",
    "ds=create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94ee9004804be8507c885af7d6ef06773b2f6752",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randomly sampling 20000 datapoints of category 1\n",
    "print(ds['Type'].unique())\n",
    "print(ds['Type'].value_counts())\n",
    "ds_t1=ds[ds['Type']==1]\n",
    "print(len(ds_t1))\n",
    "ds_t2=ds[(ds['Type']==2)|(ds['Type']==3)|(ds['Type']==4)|(ds['Type']==5)]\n",
    "print(len(ds_t2))\n",
    "print(len(ds))\n",
    "ds_t1_sampled=ds_t1.sample(20000)\n",
    "ds=pd.concat([ds_t1_sampled,ds_t2],axis=0)\n",
    "print(ds['Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d0c630b584f07c9a8587f6675416c895de86713"
   },
   "source": [
    "# Saving dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef2d429c36beb0e82662576cf759b09023e3acf6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.to_csv('dataset.csv',index=False)\n",
    "df=pd.read_csv('dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4187a30771a7de8051fae5a63005284c07ef7bc1"
   },
   "source": [
    "# Test train split for training the Random Forest Classifier and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4fb263c539de7492587c37974bb4e6c42b9d14e3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('phase1')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(ds.iloc[:,0:51],ds.iloc[:,51] , test_size = 0.25)\n",
    "\n",
    "print('phase2')\n",
    "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)\n",
    "print(type(X_train))\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d1ba36b097ee9896aacb9c16d1824fe7800345f"
   },
   "source": [
    "# Training Algo. 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b2fce501afc04a66cbff2d7df40e9967f2641e3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "clf2 = RandomForestClassifier(n_estimators=100 ,random_state=1)\n",
    "clf2.fit(X_train, Y_train)\n",
    "pre = clf2.predict(X_test)\n",
    "\n",
    "#Saving model\n",
    "filename = 'random_forest2.sav'\n",
    "joblib.dump(clf2, filename)\n",
    "\n",
    "#Using Current Classfier\n",
    "print('phase4')\n",
    "pre=clf2.predict(X_test)\n",
    "\n",
    "#Printing the accuracy score\n",
    "print('phase5')\n",
    "print(accuracy_score(Y_test,pre))\n",
    "print(confusion_matrix(Y_test, pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c705934f3a99b4a33cb353afd3dd43e287c3838b"
   },
   "source": [
    "# Training Algo. 2: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c84929cb54b26b6333434f45c64c25088942aea",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decison tree classifier\n",
    "clf3 = DecisionTreeClassifier()\n",
    "clf3=clf3.fit(X_train,Y_train)\n",
    "pre=clf3.predict(X_test)\n",
    "\n",
    "#Saving model\n",
    "filename = 'Decison_Tree2.sav'\n",
    "joblib.dump(clf3, filename)\n",
    "\n",
    "#Using Current Classfier\n",
    "print('phase4')\n",
    "pre=clf3.predict(X_test)\n",
    "\n",
    "#Printing the accuracy score\n",
    "print('phase5')\n",
    "print(accuracy_score(Y_test,pre))\n",
    "print(confusion_matrix(Y_test, pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae126cc14a58e7099309b22ac042432c26b7e2bd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bd2a57814ccd97d421586029fb635ff88f2d569"
   },
   "source": [
    "# Pan Tompkin's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4bb58d0b73835219a083e968521c70035100f80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(high):\n",
    "    tot=len(high)\n",
    "    ##--DERIVATIVE\n",
    "    deri=[]\n",
    "    high=[0]*2+high+[0]*2\n",
    "    for i in range(2,tot+2):\n",
    "        deri.append((2*high[i+1]-2*high[i-1]+high[i+2]-high[i-2])/8)\n",
    "    high=high[2:-2]\n",
    "#     print(len(deri),len(high))\n",
    "    for i,j in enumerate(deri):\n",
    "        deri[i]*=3\n",
    "#     time=[i/360 for i in range(2000)]\n",
    "#     plt.plot(time,high[:2000],c='r',label='Bandpass signal')\n",
    "#     plt.plot(time,deri[:2000],c='b',label='Derivative output')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.ylabel('Voltage (in mv)')\n",
    "#     plt.title('Plot between Bandpass signal and Derivative output')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    ##--SQUARE\n",
    "    sq=[]\n",
    "    for i in range(len(deri)):\n",
    "        sq.append(deri[i]*deri[i])\n",
    "#     plt.plot(time,high[:2000],c='r',label='Bandpass signal')\n",
    "#     plt.plot(time,sq[:2000],c='b',label='Squared output')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.ylabel('Voltage (in mv)')\n",
    "#     plt.title('Plot between Bandpass signal and Square output')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    ##--MOVING AVERAGE\n",
    "    mv=[]\n",
    "    n=30\n",
    "    sq=[0]*n+sq+[0]*n\n",
    "    for i in range(n,len(deri)+n):\n",
    "        mv.append(sum(sq[i:i+n])/n)\n",
    "    sq=sq[n:-n]\n",
    "#     print(len(mv),len(mv))\n",
    "    for i,j in enumerate(mv):\n",
    "        mv[i]*=2\n",
    "#     plt.plot(time,high[:2000],c='r',label='Bandpass signal')\n",
    "#     plt.plot(time,mv[:2000],c='b',label='Moving Average output')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.ylabel('Voltage (in mv)')\n",
    "#     plt.title('Plot between Bandpass signal and Moving Average output')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    return mv\n",
    "\n",
    "mv=preprocessing(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d70e5e63962e7dbdba20852bca39c493ce8db474",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaptive_thresholding(mv,bandpass_output):\n",
    "    ##--THRESHOLD\n",
    "    spk,npk,thresh,beat_count,prev=0,0,0,0,False\n",
    "    thresh1=[]\n",
    "    index_arr=[]\n",
    "    for j,i in enumerate(mv):\n",
    "        if i>thresh:\n",
    "            spk=0.125*i+0.875*spk\n",
    "        else:\n",
    "            npk=0.125*i+0.875*npk\n",
    "        thresh=0.75*npk+0.25*spk\n",
    "        thresh1.append(200*thresh)\n",
    "        if i>thresh and prev==False:\n",
    "            beat_count+=1\n",
    "            prev=True\n",
    "            index_arr.append(j)\n",
    "        if i<thresh and prev==True:\n",
    "            prev=False\n",
    "#     print(len(thresh1))\n",
    "    for i,j in enumerate(thresh1):\n",
    "        thresh1[i]/=20\n",
    "#     time=[i/360 for i in range(2000)]\n",
    "#     plt.plot(time,bandpass_output[:2000],c='r',label='Bandpass signal')\n",
    "#     plt.plot(time,thresh1[:2000],c='b',label='Adaptive threshold output')\n",
    "#     plt.xlabel('Time (in sec)')\n",
    "#     plt.ylabel('Voltage (in mv)')\n",
    "#     plt.title('Plot between Bandpass signal and Adaptive threshold output')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    \n",
    "    return beat_count,index_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b7f18f401bc9c614475825ef1c12d6d0e7da37a"
   },
   "source": [
    "# Testing the patients data with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8e90be484322c497a6e722883593bd24f15d82e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46693a3b87f50aa1d919f51d123cda2a08635823",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt=joblib.load('../input/trained-randomforest/Decison_Tree2.sav')\n",
    "rf=joblib.load('../input/trained-randomforest/random_forest2.sav')\n",
    "def testing():\n",
    "    dataset=pd.DataFrame(columns=['f{}'.format(i) for i in range(50)]+['Sample#'])\n",
    "    for i in test_lst:\n",
    "        print('{} is processing'.format(i))\n",
    "        df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n",
    "        if i in [102,104]:\n",
    "            df=df[[\"'sample #'\",\"'V5'\"]]\n",
    "            df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n",
    "        else:\n",
    "            df=df[[\"'sample #'\",\"'MLII'\"]]\n",
    "            df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n",
    "        df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n",
    "#         Filtering\n",
    "        bandpass_output=filtering(df['ML'])\n",
    "#         Preprocessing\n",
    "        mv=preprocessing(bandpass_output)\n",
    "#         Adaptive Thresholding\n",
    "        beat_count,beat_index=adaptive_thresholding(mv,bandpass_output)\n",
    "#         Interpolation\n",
    "        total_peaks=interpolation(beat_index,bandpass_output)\n",
    "#         Discrete Wavelet Transform\n",
    "        CA,CD=wavelet_transform(total_peaks)\n",
    "#         RR interval feature\n",
    "        temp_df=pd.DataFrame([i-j for i, j in zip(beat_index[1:],beat_index[:-1])] , columns=['Sample#'])\n",
    "#         Creating the dataframe of CA (numpy array)\n",
    "        DS=creating_dataframe(CA)\n",
    "        DS=pd.concat([DS, temp_df] ,axis=1)\n",
    "        \n",
    "        calc_rf=rf.predict(DS)\n",
    "        calc_dt=dt.predict(DS)\n",
    "        print('Classification using Random forest algorithm for patient no.{}'.format(i))\n",
    "        uni,cnt=np.unique(calc_rf,return_counts=True)\n",
    "        val=sum(cnt)\n",
    "        for x,y in zip(uni,cnt):\n",
    "            print('For category {} we get {} heartbeat which makes {}% fraction of heartbeat'.format(x,y,y*100/val))\n",
    "\n",
    "        print('\\nClassification using Decision tree algorithm for patient no.{}'.format(i))\n",
    "        uni,cnt=np.unique(calc_dt,return_counts=True)\n",
    "        val=sum(cnt)\n",
    "        for x,y in zip(uni,cnt):\n",
    "            print('For category {} we get {} heartbeat which makes {}% fraction of heartbeat'.format(x,y,y*100/val))\n",
    "testing()\n",
    "# type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7f460e4a7dcb67a695a610da97646dca5f2f300"
   },
   "source": [
    "# Creating the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1192adc04b2748a77b21607a4d05875be948f0a3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion(beat_ind,an):\n",
    "    tp,fp,fn=0,0,0\n",
    "    i,j=0,0\n",
    "    while i<len(beat_ind) and j<len(an['Sample#']):\n",
    "        if abs(beat_ind[i]-an['Sample#'][j])<40:\n",
    "            i+=1\n",
    "            j+=1\n",
    "            tp+=1\n",
    "        elif beat_ind[i]>an['Sample#'][j]+50:\n",
    "            j+=1\n",
    "        else:\n",
    "            i+=1\n",
    "    fp=len(beat_ind)-tp\n",
    "    fn=len(an['Sample#'])-tp\n",
    "    return pd.DataFrame({'Total original beats':[len(an['Sample#'])],'Total predicted beats':[len(beat_ind)],'TP':[tp],'FP':[fp],'FN':[fn]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f9700b0551a6512f4acec7eb71002e278f9fb6d",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_table=pd.DataFrame(columns=['Total original beats','Total predicted beats','TP','FP','FN'])\n",
    "for i in lst1:\n",
    "    print('{} is processing'.format(i))\n",
    "    df=pd.read_csv(\"../input/mitbih-database/mitbih_database/{}.csv\".format(i))\n",
    "    an=pd.read_csv(\"../input/annoation/{}annotations.csv\".format(i))\n",
    "    an=an[['Sample#']]\n",
    "    if i in [102,104]:\n",
    "        df=df[[\"'sample #'\",\"'V5'\"]]\n",
    "        df.rename(columns={\"'V5'\":\"ML\"},inplace=True)\n",
    "    else:\n",
    "        df=df[[\"'sample #'\",\"'MLII'\"]]\n",
    "        df.rename(columns={\"'MLII'\":\"ML\"},inplace=True)\n",
    "    df[\"ML\"]=(df[\"ML\"]-1024)*0.005\n",
    "#         Filtering\n",
    "    bandpass_output=filtering(df['ML'])\n",
    "#         Preprocessing\n",
    "    mv=preprocessing(bandpass_output)\n",
    "#         Adaptive Thresholding\n",
    "    beat_count,beat_index=adaptive_thresholding(mv,bandpass_output)\n",
    "#     Creating the confusion matrix for current patient\n",
    "    cf=confusion(beat_index,an)\n",
    "    confusion_table=pd.concat([confusion_table,cf])\n",
    "print(confusion_table)\n",
    "print('Sensitivity {}'.format(confusion_table['TP'].sum()/(confusion_table['TP'].sum()+confusion_table['FN'].sum())))\n",
    "print('Positive Predictivity {}'.format(confusion_table['TP'].sum()/(confusion_table['TP'].sum()+confusion_table['FP'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc491d7385fa78096eaa65ca3263ed1c8628ccda",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
